{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87c96d40-a4e9-43e6-ac92-6234ddbb7832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DBC_10 Quiz: Material Master Data: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf6bfa1a-86b7-40f0-9459-9574421a758f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6346b999-d5cf-4057-88b6-d73e57062112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8179911-2719-4064-947b-922c325e88b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Rules\n",
    "\n",
    "- Rule 1: `material_id` should not be null\n",
    "- Rule 2: `unit_cost` should be greater than 0\n",
    "- Rule 3: `status` should not be null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "719749ae-94aa-46a3-9dd9-34e764faf3d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dataset Rules\n",
    "# Pipelines Expectations\n",
    "\n",
    "dataset_rules = {\n",
    "  \"R1\": \"material_id is not null\",\n",
    "  \"R2\": \"unit_cost > 0\",\n",
    "  \"R3\": \"status is not null\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc1a3c92-f6cc-4b29-a779-29c3799622d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze Layer Implementation\n",
    "\n",
    "Read and store raw files as-is from Databricks `Volume` to `Source Table` and Copy Stream to Bronze Layer `bronze_mmd_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "728e8309-1f85-4f25-b8e2-4f6a57b30c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bronze Layer Implementation\n",
    "@dlt.table\n",
    "@dlt.expect_all(dataset_rules)\n",
    "def bronze_mmd_data():\n",
    "    df = spark.readStream \\\n",
    "        .format(\"delta\") \\\n",
    "        .option(\"readChangeFeed\", \"true\") \\\n",
    "        .table(\"workspace.mmd_schema.source_mmd_data\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "382a1b99-dc05-4fd9-b086-361d18ac5912",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Silver Layer Implementation\n",
    "\n",
    "Stream data from the bronze layer `bronze_mmd_data`, drop rows that do not meet `dataset rules`, and cast columns to appropriate `datatypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "162e2ff9-9636-4253-98ce-511e99f20033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table\n",
    "@dlt.expect_all_or_drop(dataset_rules)\n",
    "def silver_mmd_data():\n",
    "    df = spark.readStream.table(\"LIVE.bronze_mmd_data\")\n",
    "    df = df.withColumn(\"unit_cost\", df.unit_cost.cast(DoubleType()))\n",
    "    df = df.withColumn(\"last_updated\", col(\"last_updated\").cast(DateType()))\n",
    "    df = df.withColumn(\"lead_time_days\", col(\"lead_time_days\").cast(IntegerType()))\n",
    "    df = df.withColumn(\"safety_stock\", col(\"safety_stock\").cast(IntegerType()))\n",
    "    df = df.withColumn(\"reorder_level\", col(\"reorder_level\").cast(IntegerType()))\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MMD-Data-Processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
